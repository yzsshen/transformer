{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Implementation\n",
    "\n",
    "Following [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# import pandas as pd\n",
    "import polars as pl  # Polars because we're cool like that\n",
    "import altair as alt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# # Can't import torchtext with ROCm\n",
    "# from torchtext.data.functional import to_map_style_dataset\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "# import torchtext.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False to skip notebook execution (e.g. for debugging)\n",
    "RUN_EXAMPLES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience helper functions\n",
    "def is_interactive_notebook() -> bool:\n",
    "    \"\"\"Returns a boolean if it is run in an interactive notebook.\"\"\"\n",
    "    return __name__ == \"__main__\"\n",
    "\n",
    "\n",
    "def show_example(fn, args=[]):\n",
    "    \"\"\"Returns the result of a function with arguments if RUN_EXAMPLES is set to True\"\"\"\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "\n",
    "def execute_example(fn, args=[]) -> None:\n",
    "    \"\"\"Executes function with arguments if RUN_EXAMPLES is set to True without returning\"\"\"\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        fn(*args)\n",
    "\n",
    "\n",
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Model Architecture\n",
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard Encoder-Decoder architecture for neural sequence transductions. Encoder maps input sequences of symbol representations to a continuous representation. The decoder generates an output sequence of symbols autoregressively.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        \"\"\"Encodes source sequence with a mask.\"\"\"\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        \"\"\"Decodes representation from memory and compares to target with mask.\"\"\"\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked source and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Defines a standard linear + softmax generation step.\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer architecture looks like this:\n",
    "\n",
    "![Transformer Architecture](transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Encoder uses a stack of $N = 6$ layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"\"\"Create N identical layers of a module.\"\"\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder uses [layer normalization](https://arxiv.org/abs/1607.06450) after each set of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"Layer Normalization module.\"\"\"\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalize\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder also uses a [residual connection](https://arxiv.org/abs/1512.03385) around each of the two sub-layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual connection with layer norm and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"\"\"Apply residual conection to sublayers with layer norm and dropout\"\"\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer norm, residual connections, and multiple layers are used to form the core encoder. The output of each sublayer is $LayerNorm(x + Sublayer(x))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Core encoder as a stack of N encoder layers with Layer Normalization.\"\"\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"Pass input and mask through each layer and then normalize.\"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder layer has two sublayers:\n",
    "1. Multi-head self-attention\n",
    "2. Position-wise fully connected feed-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Full encoder layer with self-attn and feed forward.\"\"\"\n",
    "\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"Use masked self-attn and feed forward networks.\"\"\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "Also uses $N = 6$ identical layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Masked N layer decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder uses the self-attention and feed forward sub-layers, but also adds a sub-layer that performs multi-head attention over the output of the encoder stack (cross-attention). Residual connections and layer norms are still used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"Decoder uses self-attn, cross-attn (from src), and feed forward.\"\"\"\n",
    "\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention sub-layer in the decoder stack needs a causal mask to prevent positions from attending to subsequent positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mask(size):\n",
    "    \"\"\"Mask out subsequent positions.\"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    causal_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(torch.uint8)\n",
    "    return causal_mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of what the causal mask looks like\n",
    "def example_mask():\n",
    "    mask = causal_mask(20)\n",
    "    LS_data = pl.concat(\n",
    "        [\n",
    "            pl.DataFrame(\n",
    "                {\n",
    "                    \"Causal Mask\": mask[0][x, y].flatten().item(),\n",
    "                    \"Window\": y,\n",
    "                    \"Masking\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(20)\n",
    "            for x in range(20)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect()\n",
    "        .properties(height=300, width=300)\n",
    "        .encode(\n",
    "            x=\"Window:O\",\n",
    "            y=\"Masking:O\",\n",
    "            color=alt.Color(\n",
    "                \"Causal Mask:N\",\n",
    "                scale=alt.Scale(domain=[True, False], range=[\"limegreen\", \"gray\"]),\n",
    "            ),\n",
    "        )\n",
    "        # .interactive()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a0c65f294287433ca49fbe16dad8e105.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a0c65f294287433ca49fbe16dad8e105.vega-embed details,\n",
       "  #altair-viz-a0c65f294287433ca49fbe16dad8e105.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a0c65f294287433ca49fbe16dad8e105\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a0c65f294287433ca49fbe16dad8e105\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a0c65f294287433ca49fbe16dad8e105\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f1b97723538ff2c2d74bafef59f73075\"}, \"mark\": {\"type\": \"rect\"}, \"encoding\": {\"color\": {\"field\": \"Causal Mask\", \"scale\": {\"domain\": [true, false], \"range\": [\"limegreen\", \"gray\"]}, \"type\": \"nominal\"}, \"x\": {\"field\": \"Window\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Masking\", \"type\": \"ordinal\"}}, \"height\": 300, \"width\": 300, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-f1b97723538ff2c2d74bafef59f73075\": [{\"Causal Mask\": true, \"Window\": 0, \"Masking\": 0}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 1}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 2}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 3}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 4}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 5}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 6}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 0, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 1, \"Masking\": 0}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 1}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 2}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 3}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 4}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 5}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 6}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 1, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 2, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 2, \"Masking\": 1}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 2}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 3}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 4}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 5}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 6}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 2, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 3, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 3, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 3, \"Masking\": 2}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 3}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 4}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 5}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 6}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 3, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 4, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 4, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 4, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 4, \"Masking\": 3}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 4}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 5}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 6}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 4, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 5, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 5, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 5, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 5, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 5, \"Masking\": 4}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 5}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 6}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 5, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 6, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 6, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 6, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 6, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 6, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 6, \"Masking\": 5}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 6}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 6, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 7, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 7, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 7, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 7, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 7, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 7, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 7, \"Masking\": 6}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 7, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 8, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 8, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 8, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 8, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 8, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 8, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 8, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 8, \"Masking\": 7}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 8, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 9, \"Masking\": 8}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 9, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 10, \"Masking\": 9}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 10, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 11, \"Masking\": 10}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 11, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 10}, {\"Causal Mask\": false, \"Window\": 12, \"Masking\": 11}, {\"Causal Mask\": true, \"Window\": 12, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 12, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 12, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 12, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 12, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 12, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 12, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 12, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 10}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 11}, {\"Causal Mask\": false, \"Window\": 13, \"Masking\": 12}, {\"Causal Mask\": true, \"Window\": 13, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 13, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 13, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 13, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 13, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 13, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 13, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 10}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 11}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 12}, {\"Causal Mask\": false, \"Window\": 14, \"Masking\": 13}, {\"Causal Mask\": true, \"Window\": 14, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 14, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 14, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 14, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 14, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 14, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 10}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 11}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 12}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 13}, {\"Causal Mask\": false, \"Window\": 15, \"Masking\": 14}, {\"Causal Mask\": true, \"Window\": 15, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 15, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 15, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 15, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 15, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 10}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 11}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 12}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 13}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 14}, {\"Causal Mask\": false, \"Window\": 16, \"Masking\": 15}, {\"Causal Mask\": true, \"Window\": 16, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 16, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 16, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 16, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 10}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 11}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 12}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 13}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 14}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 15}, {\"Causal Mask\": false, \"Window\": 17, \"Masking\": 16}, {\"Causal Mask\": true, \"Window\": 17, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 17, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 17, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 10}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 11}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 12}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 13}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 14}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 15}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 16}, {\"Causal Mask\": false, \"Window\": 18, \"Masking\": 17}, {\"Causal Mask\": true, \"Window\": 18, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 18, \"Masking\": 19}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 0}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 1}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 2}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 3}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 4}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 5}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 6}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 7}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 8}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 9}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 10}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 11}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 12}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 13}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 14}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 15}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 16}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 17}, {\"Causal Mask\": false, \"Window\": 19, \"Masking\": 18}, {\"Causal Mask\": true, \"Window\": 19, \"Masking\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_example(example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Attention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.10",
   "language": "python",
   "name": "py_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
